#############################################################################################
utorid: wangw222
name: WEIZHOU WANG
email: weizhou.wang@mail.utoronto.ca
#############################################################################################
1. Why is it important to #ifdef out methods and datastructures that arenâ€™t used for different versions of randtrack? 

With #ifdef, the code that does not belong to the current version will be ignored and not be compiled. If we do not use 
#ifdef, those methods and data structures for other versions will increase the size of the compiled object files, which 
results in a worse locality (and the initialization and clean-up of extra data structures will also slow down the program), 
so the program will run slower than expected and the performance will be affected. In addition, without #ifdef, it might 
be harder for the developers to read or debug the code because they need extra time to distinguish which version the data 
structures or methods belong to. As a result, it is easier to have bugs or conflicts because the developer may mistakenly 
use the methods in the wrong version (or mistakenly run redundant code from two versions together).

2. Can you implement this without modifying the hash class, or without knowing its internal implementation?

We can implement this without modifying the hash class, but we have to know its internal implementation. We can create an 
array of locks, where each lock is responsible for an element in the "entries" array, i.e. each lock corresponds to a list 
(and the total number of lists has been given in the randtrack file). The lock can be added in the randtrack file, and be 
applied when the threads accesse the lists or list elements. However, to do so, we need to know how the hash class is 
implemented, especially how the hash index is computed (i.e. the implementation of HASH_INDEX macro), so that we know which 
keys belong to the same list. (Assume this index computation counts as the "internal implementation").

3. Can you properly implement this solely by modifying the hash class methods lookup and insert? Explain. 

No. First, the hash table is also modified outside the hash class methods, i.e. "s->count++" in randtrack, because the increment 
operation is not atomic, so we have to put this modification into the critical section as well to avoid the race condition. 
Second, it is possible that there is an element inserted in between the lookup() and insert(), so we need to put them in 
one critical section, otherwise, there might be two same elements inserted redundantly. 

4. Can you implement this by adding to the hash class a new function lookup and insert if absent? Explain. 

Yes, we can, because this prevents the situation where multiple threads insert the same element. However, other than the new 
function needed to be in a critical section, the "s->count++" in randtrack still need to be protected, as discussed in the 
previous question (but we can move this inside the lookup_and_insert()).

5. Can you implement it by adding new methods to the hash class lock list and unlock list? Explain. 

Yes, we can. We will have an array of locks in the hash class, where each one corresponds to a hash table entry list. The input 
to lock_list() and unlock_list() will be the key value, and the methods will compute the corresponding hash index to locate the 
corresponding lock. By doing so we have a separate lock for each list, then we can use them in the randtrack file to ensure correct 
behaviour when the hash table is being accessed or modified (e.g. lock before lookup(), unlock after increment). Other than that, 
we also need to initialize and free the locks in the methods setup() and cleanup().

6. TM. Ignored

7. What are the pros and cons of this approach?
Pros:
    a. We do not need mutex locks anymore. It helps to improve the performance when different threads work concurrently/in parallel 
       because they do not need to worry about waiting for a lock on the critical section, so there will be no locking overhead anymore.
    b. It is easier to implement than using locks because developers do not need to worry about identifying critical sections or ensuring 
       synchronizations on shared data structures when the threads are working together (we do need to merge the hash tables after all 
       threads finish though). It prevents to have race conditions because each thread has a separate hash table.
    c. It provided more scalability when there is an increasing number of random numbers because there is no lock contention anymore 
       (while the merging step may weaken the scalability).
Cons:
    a. Since each thread has a separate hash table, there will be more memory used than before, adding a lot of memory overhead.
    b. All hash tables need to be initialized in the beginning (and cleaned up in the end), and be merged after threads finish their jobs, 
       which adds performance overhead to the program.
    c. Although threads may access hash tables with the same index or even elements with the same key values, as threads use different hash 
       tables, the entries and elements will be stored in different cache lines, which reduces locality, and so the performance may be affected.


+-----------------------------------------------------+
| Measurement (in sec) with samples_to_skip set to 50 |
+---------------+-----------+------------+------------+
| Version       |  1 Thread |  2 Threads |  4 Threads |
+---------------+-----------+------------+------------+
| Original      |                6.694                |
+---------------+-----------+------------+------------+
| Global-lock   |   6.766   |    4.286   |    4.706   |
+---------------+-----------+------------+------------+
| List-lock     |   7.088   |    3.762   |    1.986   |
+---------------+-----------+------------+------------+
| Element-lock  |   7.482   |    4.008   |    2.104   |
+---------------+-----------+------------+------------+
| Reduction     |   6.724   |    3.390   |    1.702   |
+---------------+-----------+------------+------------+

8. For samples to skip set to 50, what is the overhead for each parallelization approach? Report this as the runtime of the parallel version with one 
   thread divided by the runtime of the single-threaded version. 

+-------------------+---------------------+
| Version           | Overhead            |
+-------------------+---------------------+
| Global-lock       | 6.766/6.694 = 1.011 |
+-------------------+---------------------+
| List-lock         | 7.088/6.694 = 1.059 |
+-------------------+---------------------+
| Element-lock      | 7.482/6.694 = 1.118 |
+-------------------+---------------------+
| Reduction Version | 6.724/6.694 = 1.004 |
+-------------------+---------------------+

9. How does each approach perform as the number of threads increases? If performance gets worse for a certain case, explain why that may have happened. 

Except for Global-lock, all other parallelization approaches performed better as the number of threads increased because there were more threads working 
in parallel. However, for the Global-lock, although using 2 threads resulted in a better performance than 1 thread, increasing the threads furthermore to 
4 would not improve the performance anymore, instead there came some extra overhead to make the elapsed time longer. The reason is that this approach used 
a coarse-grained global lock, so the lock got contended every time when there were some threads trying to access the hash table at the same time. The elapsed 
time when using 2 threads is less than when using 1 thread because the time spent by skipping samples got parallelized. However, when accessing the hash 
table, there was actually only one thread that could access the hash table at a time and so the hash table modification would not be parallelized and accelerated 
by the threads and became the bottleneck. Furthermore, when adding more threads, it brought in more overhead such as thread initialization, and the locking 
overhead (e.g. blocking, wakeup, and the fact that coarse-grained locking may increase cache misses from cohenrence protocol, as discussed in lecture), which 
cancelled out the acceleration in parallelizing sample skipping, resulted in an increased time overall.

10. Repeat the data collection above with samples to skip set to 100 and give the table. How does this change impact the results compared with when set to 50? Why? 

+------------------------------------------------------+
| Measurement (in sec) with samples_to_skip set to 100 |
+----------------+-----------+------------+------------+
| Version        |  1 Thread |  2 Threads |  4 Threads |
+----------------+-----------+------------+------------+
| Original       |                13.144               |
+----------------+-----------+------------+------------+
| Global-lock    |   13.240  |    7.286   |    4.750   |
+----------------+-----------+------------+------------+
| List-lock      |   13.510  |    6.994   |    3.610   |
+----------------+-----------+------------+------------+
| Element-lock   |   13.882  |    7.192   |    3.738   |
+----------------+-----------+------------+------------+
| Reduction      |   13.196  |    6.624   |    3.316   |
+----------------+-----------+------------+------------+

As the number of skipping samples increased from 50 to 100, the elapsed time in all cases except when using Global-lock with 4 threads, became much longer (~1.9x) than 
before as it took more time to skip the samples in all threads. For Global-lock with 4 threads, the elapsed time did not have a significant difference because the bottleneck, 
which is the hash table modification, stayed the same as before. Although each thread spent more time in sample skipping, this can be accelerated by parallelization, while 
after this is done, the threads still needed to wait for the lock to become available. Also, the thread and locking overhead slowed down the performance as discussed in the 
previous question. Therefore, the bottleneck stayed the same and the elapsed time, in this case, did not change much. However, when using Global-lock, the trend became different 
than when samples_to_skip=50, where the elapsed time became longer when the number of threads decreases. The reason is that, when the number of threads is 1 or 2, each thread 
spent a longer time in sample skipping, so the elapsed time was dominated by the increased samples_to_skip resulting in longer elapsed times.

11. Which approach should OptsRus ship? Keep in mind that some customers might be using multicores with more than 4 cores, while others might have only one or two cores. 

The OptsRus should ship the Reduction Version approach, as it has the smallest elapsed time when the number of threads is larger than one, which gives the best performance 
for users having more than one core and the performance will have significant improvement than the Original Randtrack. For users having only one core, the elapsed time for 
the Reduction Version stays similar to the Original Randtrack, because it does not use locking, resulting in less overhead. Therefore, for users who only have one core, 
the Reduction Version approach will not give them an obvious performance drop-down, so they will have the same experience as before. In comparison, the other locking approaches have 
more elapsed time than the original when thread=1, which will give the 1-core users worse experiences, resulting in user loss. As a result, the company should choose the 
Reduction Version. (Here we assume that the elapsed time is more important than memory usage).